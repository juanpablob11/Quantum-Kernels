{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "037a6c83-ab00-4c25-a21b-6a997e963eb9",
   "metadata": {},
   "source": [
    "# Quantum Kernels Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29525a8b-1a89-4a27-ace4-59cf64fe3d0f",
   "metadata": {},
   "source": [
    "In this cell we construct a small synthetic data set inspired by the discrete logarithm problem (DLP), following the setting of Ref. [1].\n",
    "\n",
    "We fix a prime modulus $p$ and work in the multiplicative group\n",
    "$$\n",
    "  \\mathbb{Z}_p^{\\ast} = \\{1,2,\\dots,p-1\\}.\n",
    "$$\n",
    "First, we find a generator $g$ of $\\mathbb{Z}_p^{\\ast}$ and build a lookup table for the discrete logarithm\n",
    "$$\n",
    "  \\log_g : \\mathbb{Z}_p^{\\ast} \\to \\{0,1,\\dots,p-2\\},\n",
    "$$\n",
    "so that for each $x$ we know the unique exponent $k$ with $g^k \\equiv x \\pmod{p}$.\n",
    "\n",
    "We then choose a random ``secret shift'' $s \\in \\{0,\\dots,p-2\\}$ and define binary labels via\n",
    "$$\n",
    "  y(x) =\n",
    "  \\begin{cases}\n",
    "    +1, & \\text{if } (\\log_g x - s) \\bmod (p-1) < \\dfrac{p-1}{2},\\\\[4pt]\n",
    "    -1, & \\text{otherwise.}\n",
    "  \\end{cases}\n",
    "$$\n",
    "Thus the exponent circle is cut into two contiguous halves, producing a balanced binary classification problem on $\\mathbb{Z}_p^{\\ast}$.\n",
    "\n",
    "Each integer $x$ is then encoded as a bit string of length\n",
    "$$\n",
    "  n_{\\text{bits}} = \\bigl\\lceil \\log_2 p \\bigr\\rceil,\n",
    "$$\n",
    "which we interpret as input features suitable for an $n_{\\text{bits}}$-qubit system.  Finally, we shuffle all $p-1$ points, split them into an $80{:}20$ train–test partition, and return\n",
    "$(X_{\\text{train}}, y_{\\text{train}}, X_{\\text{test}}, y_{\\text{test}})$ together with a metadata dictionary containing $p$, $g$, $n_{\\text{bits}}$, the secret shift $s$, and the integer indices used in the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e1b6b5f-8b72-4611-95c0-08e0b56de2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil, log2\n",
    "from typing import Tuple, Dict, Any\n",
    "\n",
    "def is_generator(g: int, p: int) -> bool:\n",
    "    \"\"\"Check if g is a generator of Z_p^* (naive, fine for small p).\"\"\"\n",
    "    residues = set(pow(g, k, p) for k in range(1, p))\n",
    "    return len(residues) == p - 1\n",
    "\n",
    "def find_generator(p: int) -> int:\n",
    "    \"\"\"Return a generator of Z_p^* (small p, brute force is fine).\"\"\"\n",
    "    for g in range(2, p):\n",
    "        if is_generator(g, p):\n",
    "            return g\n",
    "    raise ValueError(\"No generator found – p might not be prime?\")\n",
    "\n",
    "def discrete_log_table(p: int, g: int) -> Dict[int, int]:\n",
    "    \"\"\"\n",
    "    Build a table mapping x -> k such that g^k ≡ x (mod p).\n",
    "    \"\"\"\n",
    "    table: Dict[int, int] = {}\n",
    "    value = 1  # g^0\n",
    "    for k in range(p - 1):\n",
    "        table[value] = k\n",
    "        value = (value * g) % p\n",
    "    return table\n",
    "\n",
    "def int_to_bits(x: int, n_bits: int) -> np.ndarray:\n",
    "    \"\"\"Convert integer x to a binary vector of length n_bits (MSB first).\"\"\"\n",
    "    return np.array([int(b) for b in format(x, f\"0{n_bits}b\")], dtype=float)\n",
    "\n",
    "def generate_dlp_dataset(\n",
    "    p: int = 97,              # <-- elegido para tener n_bits = 7\n",
    "    train_fraction: float = 0.8,  # 80% train / 20% test\n",
    "    seed: int = 0,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generate a DLP-inspired dataset suitable for 7 qubits.\n",
    "\n",
    "    Para el valor por defecto p=97:\n",
    "      - n_bits  = ceil(log2(97)) = 7 qubits\n",
    "      - n_total = p - 1 = 96 puntos (x = 1,...,96)\n",
    "      - train_fraction = 0.8 -> n_train ≈ 77, n_test ≈ 19\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # 1) number-theory setup\n",
    "    g = find_generator(p)                  # generator of Z_p^*\n",
    "    log_tab = discrete_log_table(p, g)     # x -> k where g^k ≡ x (mod p)\n",
    "    n_bits = ceil(log2(p))                 # number of qubits to represent 0..p-1\n",
    "\n",
    "    # 2) secret shift s in exponent space\n",
    "    s = rng.integers(0, p - 1)\n",
    "    L = (p - 1) // 2                       # length of +1 interval\n",
    "\n",
    "    def label_x(x: int) -> int:\n",
    "        \"\"\"\n",
    "        Label based on exponent k = log_g(x):\n",
    "          y = +1 if (k - s) mod (p-1) < L\n",
    "              -1 otherwise\n",
    "        \"\"\"\n",
    "        k = log_tab[x]\n",
    "        return 1 if ((k - s) % (p - 1)) < L else -1\n",
    "\n",
    "    # 3) sample all points and split into train/test\n",
    "    all_x = np.arange(1, p)  # 1..p-1  (total = p-1 points)\n",
    "    rng.shuffle(all_x)\n",
    "\n",
    "    n_total = len(all_x)               # = p-1\n",
    "    n_train = int(round(train_fraction * n_total))\n",
    "    n_test  = n_total - n_train\n",
    "\n",
    "    x_train_int = all_x[:n_train]\n",
    "    x_test_int  = all_x[n_train:n_train + n_test]\n",
    "\n",
    "    # 4) build features and labels\n",
    "    X_train = np.vstack([int_to_bits(int(x), n_bits) for x in x_train_int])\n",
    "    y_train = np.array([label_x(int(x)) for x in x_train_int])\n",
    "\n",
    "    X_test = np.vstack([int_to_bits(int(x), n_bits) for x in x_test_int])\n",
    "    y_test = np.array([label_x(int(x)) for x in x_test_int])\n",
    "\n",
    "    meta: Dict[str, Any] = {\n",
    "        \"p\": p,\n",
    "        \"g\": g,\n",
    "        \"n_bits\": n_bits,\n",
    "        \"s\": int(s),\n",
    "        \"x_train_int\": x_train_int,\n",
    "        \"x_test_int\": x_test_int,\n",
    "    }\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6827572-2e64-4a93-8c9f-0dac9276bd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p': 97, 'g': 5, 'n_bits': 7, 's': 81, 'x_train_int': array([96, 37, 21,  6, 24, 17, 75, 68, 53, 28, 40, 14, 92, 35, 12, 11, 81,\n",
      "        9, 38, 10, 73, 63, 20, 91, 85, 84, 43, 88,  5, 26, 58, 95, 89, 45,\n",
      "       56, 51, 69, 82, 16, 31,  3, 36, 61, 44, 18, 72, 29, 83, 19, 67,  4,\n",
      "        2, 54, 25, 66, 22, 48,  1,  7, 65, 46, 23, 71, 27, 52, 50, 76, 90,\n",
      "       93, 41, 62, 13, 33, 94, 47, 59, 15]), 'x_test_int': array([74, 39, 86, 32, 87, 49, 78, 77,  8, 64, 70, 79, 60, 55, 30, 42, 57,\n",
      "       34, 80])}\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, meta = generate_dlp_dataset()\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b889f25-8038-45f5-926d-2cdf79630b81",
   "metadata": {},
   "source": [
    "# Quantum Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8628f875-016d-4aa7-9eb4-d11f63e21b3a",
   "metadata": {},
   "source": [
    "We define a helper function, `build_feature_circuit_from_map`, to turn a parameterized Qiskit feature map (e.g., `ZFeatureMap` or `ZZFeatureMap`) into a concrete circuit for a specific data point $\\mathbf{x}$.\n",
    "\n",
    "For a given input vector $\\mathbf{x} = (x_1,\\dots,x_d)$, the function binds the circuit parameters to rotation angles:\n",
    "$$\n",
    "  \\theta_i = \\pi \\cdot x_i.\n",
    "$$\n",
    "This scaling ensures that binary features map effectively ($0 \\mapsto 0$ and $1 \\mapsto \\pi$). The function returns a bound `QuantumCircuit` representing the feature state $|\\phi(x)\\rangle$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54701596-1ba6-4988-8646-ca7a7e16dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qiskit.circuit import QuantumCircuit\n",
    "\n",
    "def build_feature_circuit_from_map(feature_map: QuantumCircuit,\n",
    "                                   x_row: np.ndarray,\n",
    "                                   angle_scale: float = np.pi) -> QuantumCircuit:\n",
    "    \"\"\"\n",
    "    Given:\n",
    "      - feature_map: a parametrized QuantumCircuit (e.g. ZZFeatureMap)\n",
    "      - x_row: one data sample (shape [num_features])\n",
    "    Return:\n",
    "      - A new circuit where parameters have been assigned using x_row.\n",
    "      \n",
    "    We multiply each feature by angle_scale (e.g. 0/1 -> 0 or π).\n",
    "    \"\"\"\n",
    "    # Get the parameters in a deterministic order (x[0], x[1], ...)\n",
    "    params = sorted(feature_map.parameters, key=lambda p: p.name)\n",
    "    assert len(params) == len(x_row), (\n",
    "        f\"Mismatch: feature_map expects {len(params)} features, \"\n",
    "        f\"but got vector of length {len(x_row)}\"\n",
    "    )\n",
    "    \n",
    "    bind = {\n",
    "        param: float(x_row[i]) * angle_scale\n",
    "        for i, param in enumerate(params)\n",
    "    }\n",
    "    return feature_map.assign_parameters(bind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb08ee-0d99-4375-9a0a-1b19a4a67c0f",
   "metadata": {},
   "source": [
    "This routine, `build_kernel_matrices_for_feature_map`, estimates kernel matrices using Qiskit’s `UnitaryOverlap` and `StatevectorSampler`.\n",
    "\n",
    "For both training and test sets, it computes the kernel entries as the overlap fidelity between data points:\n",
    "$$\n",
    "  K(x_i,x_j) = |\\langle\\phi(x_i) | \\phi(x_j)\\rangle|^2 \\approx \\Pr(\\text{measuring } 0\\dots0).\n",
    "$$\n",
    "We construct the overlap circuit for each pair, estimate the probability of the all-zero outcome, and populate the train–train and test–train matrices to be used as precomputed kernels in an SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8b31cb-75d3-4bcd-887d-5c6c0a1c200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import UnitaryOverlap\n",
    "from qiskit.primitives import StatevectorSampler\n",
    "\n",
    "sampler = StatevectorSampler()  # reuse the same sampler\n",
    "\n",
    "def build_kernel_matrices_for_feature_map(feature_map: QuantumCircuit,\n",
    "                                          X_train: np.ndarray,\n",
    "                                          X_test: np.ndarray,\n",
    "                                          num_shots: int = 4096,\n",
    "                                          angle_scale: float = np.pi):\n",
    "    \"\"\"\n",
    "    For a given feature_map circuit and dataset (X_train, X_test),\n",
    "    build:\n",
    "      - kernel_matrix: train–train (n_train, n_train)\n",
    "      - test_matrix:   test–train (n_test,  n_train)\n",
    "    using UnitaryOverlap + StatevectorSampler.\n",
    "    \"\"\"\n",
    "    n_train = X_train.shape[0]\n",
    "    n_test  = X_test.shape[0]\n",
    "    \n",
    "    kernel_matrix = np.full((n_train, n_train), np.nan, dtype=float)\n",
    "    test_matrix   = np.full((n_test,  n_train), np.nan, dtype=float)\n",
    "    \n",
    "    # Local helper using our generic builder\n",
    "    def feature_circ(x_row):\n",
    "        return build_feature_circuit_from_map(feature_map, x_row, angle_scale=angle_scale)\n",
    "    \n",
    "    def kernel_entry(x_i, x_j):\n",
    "        \"\"\"K(x_i, x_j) ~ Pr(measuring 0...0 in overlap circuit.\"\"\"\n",
    "        circ_i = feature_circ(x_i)\n",
    "        circ_j = feature_circ(x_j)\n",
    "        \n",
    "        overlap_circ = UnitaryOverlap(circ_i, circ_j)\n",
    "        overlap_circ.measure_all()\n",
    "        \n",
    "        result = sampler.run([overlap_circ], shots=num_shots).result()\n",
    "        counts = result[0].data.meas.get_int_counts()\n",
    "        return counts.get(0, 0) / num_shots\n",
    "    \n",
    "    # --- train–train ---\n",
    "    for i in range(n_train):\n",
    "        kernel_matrix[i, i] = 1.0  # ⟨φ(x)|φ(x)⟩ = 1\n",
    "        for j in range(i + 1, n_train):\n",
    "            val = kernel_entry(X_train[i], X_train[j])\n",
    "            kernel_matrix[i, j] = val\n",
    "            kernel_matrix[j, i] = val\n",
    "    \n",
    "    # --- test–train ---\n",
    "    for i in range(n_test):\n",
    "        for j in range(n_train):\n",
    "            test_matrix[i, j] = kernel_entry(X_test[i], X_train[j])\n",
    "    \n",
    "    return kernel_matrix, test_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc5ecc-5c7f-43ad-a8d7-adc01bf196eb",
   "metadata": {},
   "source": [
    "We instantiate several standard Qiskit feature maps acting on $n_{\\text{features}}$ qubits to compare different encoding strategies:\n",
    "\n",
    "* **Angle Encoding:** `ZFeatureMap` (with 1 and 2 reps) using single-qubit $Z$-rotations.\n",
    "* **Entangling:** `ZZFeatureMap` (with 1 and 2 reps) adding pairwise $ZZ$ interactions.\n",
    "* **Expressive:** `PauliFeatureMap` using custom $XZ$ and $XYZ$ operator strings.\n",
    "\n",
    "Each map defines a unique quantum kernel $K_{\\text{fm}}(x,z) = |\\langle\\phi_{\\text{fm}}(x) | \\phi_{\\text{fm}}(z)\\rangle|^2$ which we will evaluate in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3988ae58-e202-44ff-9c82-134cf7c932a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import ZFeatureMap, ZZFeatureMap, PauliFeatureMap\n",
    "\n",
    "n_features = X_train.shape[1]  # should be 9\n",
    "\n",
    "feature_maps = [\n",
    "    (\"ZFeatureMap_reps1\",  ZFeatureMap(feature_dimension=n_features, reps=1)),\n",
    "    (\"ZFeatureMap_reps2\",  ZFeatureMap(feature_dimension=n_features, reps=2)),\n",
    "    (\"ZZFeatureMap_reps1\", ZZFeatureMap(feature_dimension=n_features,\n",
    "                                        reps=1, entanglement=\"linear\")),\n",
    "    (\"ZZFeatureMap_reps2\", ZZFeatureMap(feature_dimension=n_features,\n",
    "                                        reps=2, entanglement=\"linear\")),\n",
    "    (\"Pauli_XZ_reps1\",     PauliFeatureMap(feature_dimension=n_features,\n",
    "                                           reps=1, paulis=['X', 'Z'])),\n",
    "    (\"Pauli_XYZ_reps1\",    PauliFeatureMap(feature_dimension=n_features,\n",
    "                                           reps=1, paulis=['X', 'Y', 'Z'])),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a7a5fb7-7961-47b8-8443-fb2c3f2c1584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature map: ZFeatureMap_reps1 ===\n",
      "Kernel stats – diag mean=1.0000, diag std=0.0000\n",
      "Kernel stats – off-diag mean=1.0000, off-diag std=0.0000, min=1.0000, max=1.0000\n",
      "Kernel build time: 146.92 s\n",
      "ZFeatureMap_reps1 – Train accuracy: 0.506\n",
      "ZFeatureMap_reps1 – Test  accuracy: 0.474\n",
      "ZFeatureMap_reps1 – Macro precision: 0.237, macro recall: 0.500, macro F1: 0.321\n",
      "ZFeatureMap_reps1 – Weighted F1: 0.305\n",
      "Confusion matrix (rows=true [-1, 1], cols=pred [-1, 1]):\n",
      "[[ 9  0]\n",
      " [10  0]]\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      1.00      0.64         9\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.47        19\n",
      "   macro avg       0.24      0.50      0.32        19\n",
      "weighted avg       0.22      0.47      0.30        19\n",
      "\n",
      "\n",
      "=== Feature map: ZFeatureMap_reps2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel stats – diag mean=1.0000, diag std=0.0000\n",
      "Kernel stats – off-diag mean=1.0000, off-diag std=0.0000, min=1.0000, max=1.0000\n",
      "Kernel build time: 188.32 s\n",
      "ZFeatureMap_reps2 – Train accuracy: 0.506\n",
      "ZFeatureMap_reps2 – Test  accuracy: 0.474\n",
      "ZFeatureMap_reps2 – Macro precision: 0.237, macro recall: 0.500, macro F1: 0.321\n",
      "ZFeatureMap_reps2 – Weighted F1: 0.305\n",
      "Confusion matrix (rows=true [-1, 1], cols=pred [-1, 1]):\n",
      "[[ 9  0]\n",
      " [10  0]]\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      1.00      0.64         9\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.47        19\n",
      "   macro avg       0.24      0.50      0.32        19\n",
      "weighted avg       0.22      0.47      0.30        19\n",
      "\n",
      "\n",
      "=== Feature map: ZZFeatureMap_reps1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel stats – diag mean=1.0000, diag std=0.0000\n",
      "Kernel stats – off-diag mean=0.6336, off-diag std=0.1684, min=0.2441, max=1.0000\n",
      "Kernel build time: 207.43 s\n",
      "ZZFeatureMap_reps1 – Train accuracy: 0.610\n",
      "ZZFeatureMap_reps1 – Test  accuracy: 0.421\n",
      "ZZFeatureMap_reps1 – Macro precision: 0.415, macro recall: 0.417, macro F1: 0.415\n",
      "ZZFeatureMap_reps1 – Weighted F1: 0.418\n",
      "Confusion matrix (rows=true [-1, 1], cols=pred [-1, 1]):\n",
      "[[3 6]\n",
      " [5 5]]\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.38      0.33      0.35         9\n",
      "           1       0.45      0.50      0.48        10\n",
      "\n",
      "    accuracy                           0.42        19\n",
      "   macro avg       0.41      0.42      0.41        19\n",
      "weighted avg       0.42      0.42      0.42        19\n",
      "\n",
      "\n",
      "=== Feature map: ZZFeatureMap_reps2 ===\n",
      "Kernel stats – diag mean=1.0000, diag std=0.0000\n",
      "Kernel stats – off-diag mean=0.6112, off-diag std=0.1748, min=0.2090, max=1.0000\n",
      "Kernel build time: 209.55 s\n",
      "ZZFeatureMap_reps2 – Train accuracy: 0.636\n",
      "ZZFeatureMap_reps2 – Test  accuracy: 0.421\n",
      "ZZFeatureMap_reps2 – Macro precision: 0.415, macro recall: 0.417, macro F1: 0.415\n",
      "ZZFeatureMap_reps2 – Weighted F1: 0.418\n",
      "Confusion matrix (rows=true [-1, 1], cols=pred [-1, 1]):\n",
      "[[3 6]\n",
      " [5 5]]\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.38      0.33      0.35         9\n",
      "           1       0.45      0.50      0.48        10\n",
      "\n",
      "    accuracy                           0.42        19\n",
      "   macro avg       0.41      0.42      0.41        19\n",
      "weighted avg       0.42      0.42      0.42        19\n",
      "\n",
      "\n",
      "=== Feature map: Pauli_XZ_reps1 ===\n",
      "Kernel stats – diag mean=1.0000, diag std=0.0000\n",
      "Kernel stats – off-diag mean=1.0000, off-diag std=0.0000, min=1.0000, max=1.0000\n",
      "Kernel build time: 159.66 s\n",
      "Pauli_XZ_reps1 – Train accuracy: 0.506\n",
      "Pauli_XZ_reps1 – Test  accuracy: 0.474\n",
      "Pauli_XZ_reps1 – Macro precision: 0.237, macro recall: 0.500, macro F1: 0.321\n",
      "Pauli_XZ_reps1 – Weighted F1: 0.305\n",
      "Confusion matrix (rows=true [-1, 1], cols=pred [-1, 1]):\n",
      "[[ 9  0]\n",
      " [10  0]]\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      1.00      0.64         9\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.47        19\n",
      "   macro avg       0.24      0.50      0.32        19\n",
      "weighted avg       0.22      0.47      0.30        19\n",
      "\n",
      "\n",
      "=== Feature map: Pauli_XYZ_reps1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel stats – diag mean=1.0000, diag std=0.0000\n",
      "Kernel stats – off-diag mean=1.0000, off-diag std=0.0000, min=1.0000, max=1.0000\n",
      "Kernel build time: 186.00 s\n",
      "Pauli_XYZ_reps1 – Train accuracy: 0.506\n",
      "Pauli_XYZ_reps1 – Test  accuracy: 0.474\n",
      "Pauli_XYZ_reps1 – Macro precision: 0.237, macro recall: 0.500, macro F1: 0.321\n",
      "Pauli_XYZ_reps1 – Weighted F1: 0.305\n",
      "Confusion matrix (rows=true [-1, 1], cols=pred [-1, 1]):\n",
      "[[ 9  0]\n",
      " [10  0]]\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      1.00      0.64         9\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.47        19\n",
      "   macro avg       0.24      0.50      0.32        19\n",
      "weighted avg       0.22      0.47      0.30        19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/juanp_baron11/Environments/qiskit-qml/qiskit-environment/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "quantum_results = []   # will store a dict per feature map for later comparison\n",
    "\n",
    "for name, fm in feature_maps:\n",
    "    print(f\"\\n=== Feature map: {name} ===\")\n",
    "    \n",
    "    # ---------------- Kernel construction ----------------\n",
    "    t0 = time.time()\n",
    "    K_train, K_test = build_kernel_matrices_for_feature_map(\n",
    "        fm,\n",
    "        X_train,\n",
    "        X_test,\n",
    "        num_shots=512,\n",
    "        angle_scale=np.pi,   # 0/1 bits → 0 or π\n",
    "    )\n",
    "    kernel_time = time.time() - t0\n",
    "    \n",
    "    # Kernel statistics (off-diagonal)\n",
    "    n_train = K_train.shape[0]\n",
    "    diag_vals = np.diag(K_train)\n",
    "    offdiag_vals = K_train[~np.eye(n_train, dtype=bool)]\n",
    "    \n",
    "    print(f\"Kernel stats – diag mean={diag_vals.mean():.4f}, \"\n",
    "          f\"diag std={diag_vals.std():.4f}\")\n",
    "    print(f\"Kernel stats – off-diag mean={offdiag_vals.mean():.4f}, \"\n",
    "          f\"off-diag std={offdiag_vals.std():.4f}, \"\n",
    "          f\"min={offdiag_vals.min():.4f}, max={offdiag_vals.max():.4f}\")\n",
    "    print(f\"Kernel build time: {kernel_time:.2f} s\")\n",
    "    \n",
    "    # ---------------- Train SVM ----------------\n",
    "    clf = SVC(kernel=\"precomputed\", C=1.0)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    clf.fit(K_train, y_train)\n",
    "    train_time = time.time() - t1\n",
    "    \n",
    "    # Train metrics\n",
    "    y_train_pred = clf.predict(K_train)\n",
    "    acc_train = accuracy_score(y_train, y_train_pred)\n",
    "    \n",
    "    # Test metrics\n",
    "    y_pred = clf.predict(K_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Detailed metrics from classification_report\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    macro_precision = report[\"macro avg\"][\"precision\"]\n",
    "    macro_recall    = report[\"macro avg\"][\"recall\"]\n",
    "    macro_f1        = report[\"macro avg\"][\"f1-score\"]\n",
    "    weighted_f1     = report[\"weighted avg\"][\"f1-score\"]\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[-1, 1])\n",
    "    \n",
    "    # Logging\n",
    "    print(f\"{name} – Train accuracy: {acc_train:.3f}\")\n",
    "    print(f\"{name} – Test  accuracy: {acc_test:.3f}\")\n",
    "    print(f\"{name} – Macro precision: {macro_precision:.3f}, \"\n",
    "          f\"macro recall: {macro_recall:.3f}, macro F1: {macro_f1:.3f}\")\n",
    "    print(f\"{name} – Weighted F1: {weighted_f1:.3f}\")\n",
    "    print(\"Confusion matrix (rows=true [-1, 1], cols=pred [-1, 1]):\")\n",
    "    print(cm)\n",
    "    \n",
    "    # If you still want the human-readable report:\n",
    "    print(\"\\nFull classification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Store everything in a dict for later comparison / DataFrame\n",
    "    quantum_results.append({\n",
    "        \"feature_map\": name,\n",
    "        \"acc_train\": acc_train,\n",
    "        \"acc_test\": acc_test,\n",
    "        \"macro_precision\": macro_precision,\n",
    "        \"macro_recall\": macro_recall,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"weighted_f1\": weighted_f1,\n",
    "        \"kernel_time\": kernel_time,\n",
    "        \"train_time\": train_time,\n",
    "        \"kernel_diag_mean\": float(diag_vals.mean()),\n",
    "        \"kernel_diag_std\": float(diag_vals.std()),\n",
    "        \"kernel_offdiag_mean\": float(offdiag_vals.mean()),\n",
    "        \"kernel_offdiag_std\": float(offdiag_vals.std()),\n",
    "        \"kernel_offdiag_min\": float(offdiag_vals.min()),\n",
    "        \"kernel_offdiag_max\": float(offdiag_vals.max()),\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de48bc1f-64a0-4689-a624-ce4718c2f539",
   "metadata": {},
   "source": [
    "# Classical Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a6595-0ccf-4f50-81d1-f9e5b336c016",
   "metadata": {},
   "source": [
    "In this cell, we establish classical baselines using raw integer inputs rescaled to the interval $(0,1]$ via\n",
    "$$\n",
    "  \\tilde{x} = \\frac{x}{p}.\n",
    "$$\n",
    "We train two support vector machines on these 1D features:\n",
    "\n",
    "* **Linear SVM:** assumes a linear decision boundary.\n",
    "* **RBF SVM:** uses a Gaussian kernel to allow non-linear boundaries.\n",
    "\n",
    "We report the test accuracy on held-out points to serve as a simple baseline using raw numeric input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad131fe-b951-40e1-a1b6-168235b8d9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM on raw x – accuracy: 0.474\n",
      "RBF SVM on raw x – accuracy: 0.474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Raw integer features (scaled to [0,1])\n",
    "x_train_raw = meta[\"x_train_int\"].reshape(-1, 1) / meta[\"p\"]\n",
    "x_test_raw  = meta[\"x_test_int\"].reshape(-1, 1) / meta[\"p\"]\n",
    "\n",
    "lin_raw = SVC(kernel=\"linear\", C=1.0)\n",
    "lin_raw.fit(x_train_raw, y_train)\n",
    "acc_lin_raw = accuracy_score(y_test, lin_raw.predict(x_test_raw))\n",
    "print(f\"Linear SVM on raw x – accuracy: {acc_lin_raw:.3f}\")\n",
    "\n",
    "rbf_raw = SVC(kernel=\"rbf\", gamma=\"scale\", C=1.0)\n",
    "rbf_raw.fit(x_train_raw, y_train)\n",
    "acc_rbf_raw = accuracy_score(y_test, rbf_raw.predict(x_test_raw))\n",
    "print(f\"RBF SVM on raw x – accuracy: {acc_rbf_raw:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2620ea46-35f8-47e0-9b5c-0d4ae2d88829",
   "metadata": {},
   "source": [
    "We repeat the classical experiments using the bit-string encoding, where each example is a $d$-dimensional vector in $\\{0,1\\}^d$. We train:\n",
    "\n",
    "* **Linear SVM** (`kernel=\"linear\"`): searches for a hyperplane in the binary feature space.\n",
    "* **RBF SVM** (`kernel=\"rbf\"`): applies a Gaussian kernel to the bit vectors.\n",
    "\n",
    "Comparing these results to the raw-integer baselines reveals whether the binary encoding exposes more useful structure to a classical classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39890ab7-7abd-4e44-9818-a0f0a1a223af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM on bit features – accuracy: 0.632\n",
      "RBF SVM on bit features – accuracy: 0.474\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM on bit encodings\n",
    "lin_bits = SVC(kernel=\"linear\", C=1.0)\n",
    "lin_bits.fit(X_train, y_train)\n",
    "acc_lin_bits = accuracy_score(y_test, lin_bits.predict(X_test))\n",
    "print(f\"Linear SVM on bit features – accuracy: {acc_lin_bits:.3f}\")\n",
    "\n",
    "# RBF SVM on bit encodings\n",
    "rbf_bits = SVC(kernel=\"rbf\", gamma=\"scale\", C=1.0)\n",
    "rbf_bits.fit(X_train, y_train)\n",
    "acc_rbf_bits = accuracy_score(y_test, rbf_bits.predict(X_test))\n",
    "print(f\"RBF SVM on bit features – accuracy: {acc_rbf_bits:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598b26f0-4ab7-48f8-9798-3a43b05a09a9",
   "metadata": {},
   "source": [
    "Finally, we aggregate the test accuracies from all models—classical (raw and bits) and quantum. We collect the results into a list\n",
    "$$\n",
    "  \\{(\\texttt{name}, \\mathrm{Acc}_{\\text{test}})\\}\n",
    "$$\n",
    "combining the four classical baselines with the quantum kernel results stored in `quantum_results`. This list is sorted in descending order and printed as a leaderboard to directly compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01c7a941-d4e4-43b6-a4e9-bcbfd7e35272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Overall comparison by TEST accuracy (classical vs quantum) ===\n",
      "Linear SVM (bits)          accuracy = 0.632\n",
      "Linear SVM (raw x)         accuracy = 0.474\n",
      "RBF SVM (raw x)            accuracy = 0.474\n",
      "RBF SVM (bits)             accuracy = 0.474\n",
      "ZFeatureMap_reps1          accuracy = 0.474\n",
      "ZFeatureMap_reps2          accuracy = 0.474\n",
      "Pauli_XZ_reps1             accuracy = 0.474\n",
      "Pauli_XYZ_reps1            accuracy = 0.474\n",
      "ZZFeatureMap_reps1         accuracy = 0.421\n",
      "ZZFeatureMap_reps2         accuracy = 0.421\n"
     ]
    }
   ],
   "source": [
    "# Build a unified list: (name, metric) for classical + quantum\n",
    "\n",
    "# Classical models (tuples)\n",
    "all_results = [\n",
    "    (\"Linear SVM (raw x)\",  acc_lin_raw),\n",
    "    (\"RBF SVM (raw x)\",     acc_rbf_raw),\n",
    "    (\"Linear SVM (bits)\",   acc_lin_bits),\n",
    "    (\"RBF SVM (bits)\",      acc_rbf_bits),\n",
    "]\n",
    "\n",
    "# Add quantum models, using their test accuracy\n",
    "all_results += [\n",
    "    (qr[\"feature_map\"], qr[\"acc_test\"])\n",
    "    for qr in quantum_results\n",
    "]\n",
    "\n",
    "print(\"\\n=== Overall comparison by TEST accuracy (classical vs quantum) ===\")\n",
    "for name, acc in sorted(all_results, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name:25s}  accuracy = {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becd442e-980e-403c-867d-a0c41eaf160e",
   "metadata": {},
   "source": [
    "### Interpretation of Results\n",
    "\n",
    "The leaderboard shows that the **Linear SVM on bit features** achieved the highest accuracy ($0.632$). Most other models, including the raw integer baselines and the majority of quantum kernels (Z and Pauli maps), clustered around an accuracy of $0.474$.\n",
    "\n",
    "**Key Observations:**\n",
    "\n",
    "1.  **Hardness of the Problem:** The Discrete Logarithm Problem generates data that appears pseudo-random. An accuracy of $\\approx 0.47$ suggests those models are effectively guessing (near random chance for this dataset size).\n",
    "2.  **Classical Advantage:** The slight edge of the Linear SVM (bits) suggests that the binary representation captures some marginal structure of the dividing line in the exponent circle that the raw integer scaling missed.\n",
    "3.  **Quantum Performance:** The standard quantum kernels (`ZFeatureMap`, `ZZFeatureMap`, `PauliFeatureMap`) failed to outperform the classical baseline. This is expected; without a kernel specifically designed to exploit the algebraic structure of the discrete log (like Shor's period-finding structure), standard geometric embeddings perceive the cryptographically \"hard\" data as noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a8ffc-6db5-4b32-9468-66aa70baa0d9",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] Y. Liu, S. Arunachalam, and K. Temme, \"A rigorous and robust quantum speed-up in supervised machine learning,\" *Nature Physics*, vol. 17, no. 9, pp. 1013–1017, 2021. doi: 10.1038/s41567-021-01287-z."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qiskit-environment)",
   "language": "python",
   "name": "qiskit-environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
